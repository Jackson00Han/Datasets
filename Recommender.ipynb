{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxgCZDJonmORYWYsQhHGH2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jackson00Han/Datasets/blob/master/Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User-User Matching Algorithm"
      ],
      "metadata": {
        "id": "9Z7o1BI9k6px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. basic similarity score calculation algorithm\n",
        "2. content-based filtering algorithm\n",
        "3. collaborative filtering algorithm\n",
        "4. hybrid system"
      ],
      "metadata": {
        "id": "pzNz78INsx4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_EqooDhSkYYl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)"
      ],
      "metadata": {
        "id": "AXvMKzACvq9w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set seed for reproducibility (so results are consistent when generating random values)\n",
        "np.random.seed(1)\n",
        "\n",
        "# Step 1: Generate synthetic user data\n",
        "\n",
        "num_samples = 100  # Define the number of user profiles\n",
        "\n",
        "# Generate random data for each column (attributes of each user)\n",
        "names = [f\"User_{i}\" for i in range(1, num_samples + 1)]  # User names\n",
        "ages = np.random.randint(18, 65, size=num_samples)  # Ages between 18 and 64\n",
        "nationalities = np.random.choice(['USA', 'Canada', 'UK', 'Germany', 'France', 'India', 'China'], size=num_samples)\n",
        "languages = np.random.choice(['English', 'French', 'German', 'Spanish', 'Hindi', 'Chinese'], size=num_samples)\n",
        "residence_countries = np.random.choice(['USA', 'Canada', 'UK', 'Germany', 'France', 'India', 'China'], size=num_samples)\n",
        "postal_codes = np.random.randint(10000, 99999, size=num_samples)  # Random postal codes\n",
        "occupations = np.random.choice(['Engineer', 'Artist', 'Doctor', 'Lawyer', 'Teacher', 'Entrepreneur'], size=num_samples)\n",
        "marital_statuses = np.random.choice(['Single', 'Married', 'Divorced'], size=num_samples)\n",
        "books = np.random.choice(['Fiction', 'Non-fiction', 'Sci-Fi', 'Fantasy', 'Biography', 'History'], size=num_samples)\n",
        "music = np.random.choice(['Rock', 'Jazz', 'Classical', 'Pop', 'Hip-hop', 'Country'], size=num_samples)\n",
        "activity_levels = np.random.randint(1, 11, size=num_samples)  # Activity levels between 1 and 10\n",
        "mana_levels = np.random.randint(0, 101, size=num_samples)  # MANA levels between 0 and 100\n",
        "\n",
        "# Step 2: Create a DataFrame to store the user data\n",
        "\n",
        "user_data = pd.DataFrame({\n",
        "    'Name': names,\n",
        "    'Age': ages,\n",
        "    'Nationality': nationalities,\n",
        "    'Language': languages,\n",
        "    'Residence Country': residence_countries,\n",
        "    'Postal Code': postal_codes,\n",
        "    'Occupation': occupations,\n",
        "    'Marital Status': marital_statuses,\n",
        "    'Favorite Book Genre': books,\n",
        "    'Favorite Music Genre': music,\n",
        "    'Activity Level': activity_levels,\n",
        "    'MANA': mana_levels  # Adding the 'MANA' column, which is a numeric feature\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Preprocess and encode categorical features\n",
        "\n",
        "# List of categorical columns to encode\n",
        "categorical_columns = ['Nationality', 'Language', 'Residence Country', 'Occupation', 'Marital Status',\n",
        "                       'Favorite Book Genre', 'Favorite Music Genre']\n",
        "\n",
        "# Initialize LabelEncoders to convert categorical values into numeric labels\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    user_data[col + '_encoded'] = label_encoders[col].fit_transform(user_data[col])\n",
        "\n",
        "# Step 4: Prepare features for similarity calculation\n",
        "\n",
        "# Numeric features for Euclidean distance\n",
        "numeric_features = ['Age', 'Activity Level', 'MANA']\n",
        "\n",
        "# Encoded categorical features for Cosine and Jaccard similarities\n",
        "categorical_features = [col + '_encoded' for col in categorical_columns]\n",
        "\n",
        "# Step 5: Define similarity functions\n",
        "\n",
        "# Function to calculate Euclidean similarity for numeric features\n",
        "def euclidean_similarity(user1_data, user2_data, features):\n",
        "    # Euclidean distance is converted to similarity by using 1 / (1 + distance)\n",
        "    return 1 / (1 + euclidean(user1_data[features], user2_data[features]))\n",
        "\n",
        "# Function to calculate Cosine similarity for categorical features\n",
        "def cosine_similarity_features(user1_data, user2_data, features):\n",
        "    # Cosine similarity compares the angles between vectors of encoded features\n",
        "    return cosine_similarity([user1_data[features]], [user2_data[features]])[0][0]\n",
        "\n",
        "# One-hot encode categorical features for Jaccard similarity\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "onehot_encoded = onehot_encoder.fit_transform(user_data[categorical_features])\n",
        "\n",
        "# Function to calculate Jaccard similarity using one-hot encoded data\n",
        "def jaccard_similarity_onehot(user1_idx, user2_idx, onehot_encoded_data):\n",
        "    # Compare one-hot encoded vectors to measure set similarity\n",
        "    user1 = onehot_encoded_data[user1_idx]\n",
        "    user2 = onehot_encoded_data[user2_idx]\n",
        "    intersection = np.sum(np.minimum(user1, user2))\n",
        "    union = np.sum(np.maximum(user1, user2))\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "# Step 6: Define a function to calculate the overall similarity\n",
        "\n",
        "def calculate_similarity(user1_idx, user2_idx, user_data, onehot_encoded_data):\n",
        "    # Extract the data for the two users being compared\n",
        "    user1_data = user_data.iloc[user1_idx]\n",
        "    user2_data = user_data.iloc[user2_idx]\n",
        "\n",
        "    # Compute Euclidean similarity on numeric features\n",
        "    euclidean_sim = euclidean_similarity(user1_data, user2_data, numeric_features)\n",
        "\n",
        "    # Compute Cosine similarity on encoded categorical features\n",
        "    cosine_sim = cosine_similarity_features(user1_data, user2_data, categorical_features)\n",
        "\n",
        "    # Compute Jaccard similarity on one-hot encoded categorical data\n",
        "    jaccard_sim = jaccard_similarity_onehot(user1_idx, user2_idx, onehot_encoded_data)\n",
        "\n",
        "    # Combine the three similarity measures into an overall similarity score\n",
        "    overall_similarity = np.mean([euclidean_sim, cosine_sim, jaccard_sim])\n",
        "\n",
        "    return overall_similarity\n",
        "\n",
        "# Step 7: Function to compute similarities and sort them in descending order\n",
        "\n",
        "def find_most_similar_users(target_user_idx, user_data, onehot_encoded_data, numeric_features, categorical_features,top_n):\n",
        "    similarities = []\n",
        "\n",
        "    # Loop through all users and calculate the similarity with the target user\n",
        "    for user_idx in range(len(user_data)):\n",
        "        if user_idx != target_user_idx:  # Skip the target user itself\n",
        "            sim_score = calculate_similarity(target_user_idx, user_idx, user_data, onehot_encoded_data)  # Call the similarity function\n",
        "            similarities.append((user_idx, sim_score))  # Store user index and similarity score\n",
        "\n",
        "    # Sort the list of tuples by similarity score in descending order\n",
        "    sorted_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return sorted_similarities[:top_n]\n",
        "\n",
        "def recommend_for_all_users_dataframe(user_data, onehot_encoded_data, numeric_features, categorical_features, top_n):\n",
        "    # Create a list to hold results for each user\n",
        "    all_recommendations = []\n",
        "\n",
        "    # Loop through each user and get the top N similar users for that user\n",
        "    for user_idx in range(len(user_data)):\n",
        "        top_similar_users = find_most_similar_users(user_idx, user_data, onehot_encoded_data, numeric_features, categorical_features, top_n)\n",
        "        # Extract only the user indices (first element of each tuple) from the list of tuples\n",
        "        top_similar_user_indices = [user[0] for user in top_similar_users]\n",
        "        # Append the target user and their top N similar users as a row\n",
        "        all_recommendations.append([user_idx] + top_similar_user_indices)\n",
        "\n",
        "    # Create column names for the DataFrame\n",
        "    column_names = ['User'] + [f'Top_{i+1}_Similar_User' for i in range(top_n)]\n",
        "\n",
        "    # Convert the list of recommendations into a pandas DataFrame\n",
        "    recommendations_df = pd.DataFrame(all_recommendations, columns=column_names)\n",
        "\n",
        "    return recommendations_df\n",
        "\n",
        "# Example: Find the top 3 most similar users for all users and display in a DataFrame\n",
        "recommendations_df = recommend_for_all_users_dataframe(user_data, onehot_encoded, numeric_features, categorical_features, top_n=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1cdc8tyBTpT",
        "outputId": "a440832f-162d-4ab4-b78b-a26ed6f12014"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's simulate a scenario where, after using a simple algorithm to calculate user similarity and recommend the top 10 people for each user, feedback is collected a few days later. Based on the feedback, each user shows interest in 0 to 2 other users. The interest is generated by assuming it is distributed as follows:\n",
        "\n",
        "90% of the users they are interested in come from the list of 10 recommended users.\n",
        "\n",
        "10% of the users they are interested in come from other users outside the recommended list."
      ],
      "metadata": {
        "id": "duZoXzkVjn8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Second Phase for further matching\n",
        "df = user_data.select_dtypes(exclude=['object'])\n",
        "\n",
        "def generate_interest_labels(num_users, recommendations_df):\n",
        "    interest_labels = {}\n",
        "\n",
        "    for user_idx in range(num_users):\n",
        "        # Get the list of recommended users for the current user\n",
        "        recommended_users = recommendations_df.iloc[user_idx, 1:].values.tolist()  # Get recommended users\n",
        "\n",
        "        # Select the top 1 user from the recommended list (the first user in the list)\n",
        "        top_recommended_user = recommended_users[0]  # The highest-ranked user is the first one\n",
        "\n",
        "        # Assign this top recommended user as the interested user for this user\n",
        "        interest_labels[user_idx] = [top_recommended_user]  # Keep it as a list to maintain consistency\n",
        "\n",
        "    return interest_labels\n",
        "\n",
        "# Generate interest labels for 100 users\n",
        "interest_labels = generate_interest_labels(100, recommendations_df)\n",
        "\n",
        "\n",
        "\n",
        "def construct_double_tower_input(user_data, interest_labels, num_users):\n",
        "    X_user = []\n",
        "    X_recommended = []\n",
        "    y_train = []\n",
        "\n",
        "    # Iterate over all users and their interest labels\n",
        "    for user_idx in range(num_users):\n",
        "        for recommended_idx in range(num_users):\n",
        "            if user_idx != recommended_idx:  # Skip self-pairing\n",
        "                # Append user features and recommended user features\n",
        "                X_user.append(user_data.iloc[user_idx].values)\n",
        "                X_recommended.append(user_data.iloc[recommended_idx].values)\n",
        "\n",
        "                # Label is 1 if the user is interested in the recommended user, 0 otherwise\n",
        "                y_train.append(1 if recommended_idx in interest_labels[user_idx] else 0)\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    X_user = np.array(X_user)\n",
        "    X_recommended = np.array(X_recommended)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    return X_user, X_recommended, y_train\n",
        "# Call the function to construct input features\n",
        "X_user, X_recommended, y_train = construct_double_tower_input(df, interest_labels, 100)\n",
        "\n",
        "# Check the shape of the output\n",
        "print(\"X_user shape:\", X_user.shape)\n",
        "print(\"X_recommended shape:\", X_recommended.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6luw1xXTge73",
        "outputId": "7b6c52cf-6038-4b9e-e767-d18f64073be3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_user shape: (9900, 11)\n",
            "X_recommended shape: (9900, 11)\n",
            "y_train shape: (9900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale training data\n",
        "X_user_unscaled = X_user\n",
        "X_recommended_unscaled = X_recommended\n",
        "\n",
        "# Standard scaling for X_recommended (formerly item_train)\n",
        "scalerItem = StandardScaler()\n",
        "scalerItem.fit(X_recommended)\n",
        "X_recommended = scalerItem.transform(X_recommended)\n",
        "\n",
        "# Standard scaling for X_user (formerly user_train)\n",
        "scalerUser = StandardScaler()\n",
        "scalerUser.fit(X_user)\n",
        "X_user = scalerUser.transform(X_user)\n",
        "\n",
        "# Now X_user, X_recommended, and y_train are scaled"
      ],
      "metadata": {
        "id": "RH2y-bQ8ynVL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Combine the two inputs into one for oversampling purposes\n",
        "combined_inputs = np.hstack((X_user, X_recommended))\n",
        "\n",
        "# Apply SMOTE to the combined inputs and labels\n",
        "smote = SMOTE()\n",
        "combined_inputs_resampled, y_train_resampled = smote.fit_resample(combined_inputs, y_train)\n",
        "\n",
        "# Split the resampled combined inputs back into X_user and X_recommended\n",
        "X_user = combined_inputs_resampled[:, :X_user.shape[1]]\n",
        "X_recommended = combined_inputs_resampled[:, X_user.shape[1]:]"
      ],
      "metadata": {
        "id": "XEWZpNaBB4nL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj5n4e0fDP_C",
        "outputId": "947ebe1b-cd48-40f4-c775-ffa675d05bcb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7859"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train_resampled.copy()\n",
        "# Split X_recommended, X_user, and y_train into training and testing sets (80% train, 20% test)\n",
        "X_recommended_train, X_recommended_test = train_test_split(X_recommended, train_size=0.80, shuffle=True)\n",
        "X_user_train, X_user_test = train_test_split(X_user, train_size=0.80, shuffle=True)\n",
        "y_train, y_test = train_test_split(y_train, train_size=0.80, shuffle=True)\n",
        "\n",
        "# Print the shapes of the training and testing datasets\n",
        "print(f\"Recommended user (item) training data shape: {X_recommended_train.shape}\")\n",
        "print(f\"Recommended user (item) test data shape: {X_recommended_test.shape}\")\n",
        "print(f\"Target user training data shape: {X_user_train.shape}\")\n",
        "print(f\"Target user test data shape: {X_user_test.shape}\")\n",
        "print(f\"y_train training data shape: {y_train.shape}\")\n",
        "print(f\"y_test test data shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjlbMc35zYe1",
        "outputId": "494c64b6-2ac1-4b81-8503-0da165b8aa8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended user (item) training data shape: (15680, 11)\n",
            "Recommended user (item) test data shape: (3920, 11)\n",
            "Target user training data shape: (15680, 11)\n",
            "Target user test data shape: (3920, 11)\n",
            "y_train training data shape: (15680,)\n",
            "y_test test data shape: (3920,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom layer for L2 normalization\n",
        "class L2NormalizationLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.math.l2_normalize(inputs, axis=1)\n",
        "\n",
        "# Define the user and recommended user tower neural networks\n",
        "num_outputs = 32  # Increased output dimension for concatenation later\n",
        "\n",
        "user_NN = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_outputs, activation='linear')  # Output before combining\n",
        "])\n",
        "\n",
        "recommended_NN = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_outputs, activation='linear')  # Output before combining\n",
        "])\n",
        "\n",
        "# Create the user input and connect it to the user tower\n",
        "input_user = tf.keras.layers.Input(shape=(X_user.shape[1],))\n",
        "vu = user_NN(input_user)\n",
        "vu = L2NormalizationLayer()(vu)  # Normalize the output using the custom layer\n",
        "\n",
        "# Create the recommended user input and connect it to the recommended user tower\n",
        "input_recommended = tf.keras.layers.Input(shape=(X_recommended.shape[1],))\n",
        "vr = recommended_NN(input_recommended)\n",
        "vr = L2NormalizationLayer()(vr)  # Normalize the output using the custom layer\n",
        "\n",
        "# Concatenate the two feature vectors from the user and recommended user towers\n",
        "concatenated = tf.keras.layers.Concatenate()([vu, vr])\n",
        "\n",
        "# Add additional dense layers after concatenation to learn more complex relationships\n",
        "dense_combined = tf.keras.layers.Dense(64, activation='relu')(concatenated)\n",
        "dense_combined = tf.keras.layers.Dense(32, activation='relu')(dense_combined)\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(dense_combined)\n",
        "\n",
        "# Specify the inputs and output of the model\n",
        "model = tf.keras.Model([input_user, input_recommended], output)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model with additional evaluation metrics\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "oU4ZNv6ZEtgK",
        "outputId": "42491025-50fa-432d-e9dc-109630585f5c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_6 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m46,304\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_7 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m46,304\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ l2_normalization_layer_6  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ sequential_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mL2NormalizationLayer\u001b[0m)    │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ l2_normalization_layer_7  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ sequential_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mL2NormalizationLayer\u001b[0m)    │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ l2_normalization_laye… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ l2_normalization_laye… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">46,304</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">46,304</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ l2_normalization_layer_6  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L2NormalizationLayer</span>)    │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ l2_normalization_layer_7  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L2NormalizationLayer</span>)    │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ l2_normalization_laye… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ l2_normalization_laye… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,881\u001b[0m (386.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,881</span> (386.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,881\u001b[0m (386.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,881</span> (386.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the cost function as Mean Squared Error (for regression problems) or binary crossentropy if it's a classification task\n",
        "cost_fn = tf.keras.losses.BinaryCrossentropy()  # Assuming binary classification task\n",
        "\n",
        "# Define the optimizer with a learning rate\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model with the defined optimizer and loss function\n",
        "model.compile(optimizer=opt,\n",
        "              loss=cost_fn,\n",
        "              metrics=['accuracy'])  # Add accuracy as a metric\n",
        "\n",
        "# Train the model using the user and recommended user features\n",
        "# Make sure to pass the training data (X_user_train and X_recommended_train) along with the labels y_train\n",
        "history = model.fit([X_user_train, X_recommended_train], y_train, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYwFaPUK0X2F",
        "outputId": "0209c4f5-0346-418d-e82b-10f9501c4628"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4937 - loss: 0.6940\n",
            "Epoch 2/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5249 - loss: 0.6917\n",
            "Epoch 3/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5361 - loss: 0.6900\n",
            "Epoch 4/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5480 - loss: 0.6883\n",
            "Epoch 5/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5526 - loss: 0.6866\n",
            "Epoch 6/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5593 - loss: 0.6848\n",
            "Epoch 7/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5641 - loss: 0.6830\n",
            "Epoch 8/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5699 - loss: 0.6811\n",
            "Epoch 9/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5743 - loss: 0.6791\n",
            "Epoch 10/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 0.6771\n",
            "Epoch 11/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 0.6751\n",
            "Epoch 12/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5905 - loss: 0.6727\n",
            "Epoch 13/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5918 - loss: 0.6705\n",
            "Epoch 14/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 0.6684\n",
            "Epoch 15/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6030 - loss: 0.6662\n",
            "Epoch 16/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6061 - loss: 0.6638\n",
            "Epoch 17/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.6616\n",
            "Epoch 18/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6134 - loss: 0.6593\n",
            "Epoch 19/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6174 - loss: 0.6568\n",
            "Epoch 20/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6207 - loss: 0.6544\n",
            "Epoch 21/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6262 - loss: 0.6517\n",
            "Epoch 22/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: 0.6492\n",
            "Epoch 23/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6358 - loss: 0.6462\n",
            "Epoch 24/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 0.6433\n",
            "Epoch 25/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6431 - loss: 0.6401\n",
            "Epoch 26/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6488 - loss: 0.6375\n",
            "Epoch 27/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 0.6344\n",
            "Epoch 28/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6542 - loss: 0.6316\n",
            "Epoch 29/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6572 - loss: 0.6286\n",
            "Epoch 30/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.6254\n",
            "Epoch 31/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6654 - loss: 0.6225\n",
            "Epoch 32/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6660 - loss: 0.6191\n",
            "Epoch 33/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6704 - loss: 0.6160\n",
            "Epoch 34/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6733 - loss: 0.6128\n",
            "Epoch 35/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.6097\n",
            "Epoch 36/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6793 - loss: 0.6066\n",
            "Epoch 37/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 0.6037\n",
            "Epoch 38/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.6004\n",
            "Epoch 39/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.5973\n",
            "Epoch 40/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6858 - loss: 0.5939\n",
            "Epoch 41/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6889 - loss: 0.5908\n",
            "Epoch 42/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6926 - loss: 0.5874\n",
            "Epoch 43/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6975 - loss: 0.5843\n",
            "Epoch 44/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6990 - loss: 0.5810\n",
            "Epoch 45/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7012 - loss: 0.5781\n",
            "Epoch 46/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7023 - loss: 0.5747\n",
            "Epoch 47/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7061 - loss: 0.5717\n",
            "Epoch 48/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.5685\n",
            "Epoch 49/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7080 - loss: 0.5657\n",
            "Epoch 50/50\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7111 - loss: 0.5629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate([X_user_test, X_recommended_test], y_test)\n",
        "\n",
        "# Print the test results\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnNw2OT11Fe9",
        "outputId": "2ad6177f-0289-4de1-d6eb-ff1eb98b4944"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5106 - loss: 0.7857\n",
            "Test Loss: 0.7894521951675415\n",
            "Test Accuracy: 0.5068877339363098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Ttt67b3DwQ",
        "outputId": "e81c3516-4657-44bd-cd1c-45ec8f7de5fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict([X_user_test, X_recommended_test])\n",
        "\n",
        "predicted_labels = (predictions > 0.29).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfwaXnlJ3IFB",
        "outputId": "befba333-c97a-40fe-b304-946f36aa9be9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "# Display confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC11HRpu3LTB",
        "outputId": "6d0c5022-e84a-4afb-a4aa-a6f8aead7fcd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1948    0]\n",
            " [  32    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWlRXiHj4BX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}